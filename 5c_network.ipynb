{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXAYIyVPqA9IdjOGJeEI8K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faaiq123/hospital-mng.c/blob/main/5c_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhVWXqH9K6Eq"
      },
      "outputs": [],
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "from skimage import exposure\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to apply CLAHE preprocessing to the MRI images\n",
        "def apply_clahe(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(image)\n",
        "\n",
        "# Load images and masks, preprocess using CLAHE\n",
        "def load_and_preprocess_data(img_dir, mask_dir):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_file in glob.glob(f'{img_dir}/*.tif'):\n",
        "        image = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
        "        preprocessed_image = apply_clahe(image)\n",
        "        images.append(preprocessed_image)\n",
        "\n",
        "        mask_file = img_file.replace(img_dir, mask_dir)\n",
        "        mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            masks.append(mask)\n",
        "\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "# Load data\n",
        "img_dir = 'path_to_images'\n",
        "mask_dir = 'path_to_masks'\n",
        "images, masks = load_and_preprocess_data(img_dir, mask_dir)\n",
        "\n",
        "# Split dataset into 80% training and 20% testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Implementation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet_plus_plus(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Decoder path with nested connections\n",
        "    up1 = UpSampling2D(size=(2, 2))(conv2)\n",
        "    merge1 = concatenate([conv1, up1], axis=-1)\n",
        "    conv3 = Conv2D(64, 3, activation='relu', padding='same')(merge1)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv3)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "IY64n8W3n_96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Model Training and Evaluation\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the DICE score metric\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Compile and train the models\n",
        "model_unet_plus_plus = unet_plus_plus(input_shape=(256, 256, 1))\n",
        "model_unet_plus_plus.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "\n",
        "model_attention_unet = attention_unet(input_shape=(256, 256, 1))\n",
        "model_attention_unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "\n",
        "# Train the models\n",
        "history_unet_plus_plus = model_unet_plus_plus.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
        "history_attention_unet = model_attention_unet.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the models\n",
        "dice_unet_plus_plus = model_unet_plus_plus.evaluate(X_test, y_test)\n",
        "dice_attention_unet = model_attention_unet.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Nested U-Net DICE Score: {dice_unet_plus_plus[1]}')\n",
        "print(f'Attention U-Net DICE Score: {dice_attention_unet[1]}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lvoqNCJxLIX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Web Application Development\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model = load_model('best_model.h5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    nparr = np.fromstring(contents, np.uint8)\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    img = cv2.resize(img, (256, 256)) / 255.0\n",
        "    img = np.expand_dims(img, axis=[0, -1])\n",
        "\n",
        "    pred_mask = model.predict(img)\n",
        "    return {\"mask\": pred_mask.tolist()}"
      ],
      "metadata": {
        "id": "A5ionQcuoKJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import requests\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "st.title(\"Brain MRI Metastasis Segmentation\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a Brain MRI image...\", type=[\"jpg\", \"png\", \"tif\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = np.array(Image.open(uploaded_file))\n",
        "    st.image(image, caption='Uploaded MRI.', use_column_width=True)\n",
        "\n",
        "    # Call the FastAPI backend for prediction\n",
        "    files = {'file': uploaded_file.getvalue()}\n",
        "    response = requests.post(\"http://127.0.0.1:8000/predict/\", files=files)\n",
        "    pred_mask = np.array(response.json()['mask'])\n",
        "\n",
        "    st.image(pred_mask, caption='Predicted Segmentation.', use_column_width=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E6QYhEdcLZWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}